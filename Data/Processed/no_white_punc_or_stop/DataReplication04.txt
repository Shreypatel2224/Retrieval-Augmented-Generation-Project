Replicating Data Distributing Data Benefits Scalability High throughput Data volume ReadWrite load grows beyond capacity single machine Fault Tolerance High Availability application needs continue working even one machines go Latency users different parts world want give fast performance Distributed Data Challenges Consistency Updates must propagated across network Application Complexity Responsibility reading writing data distributed environment often falls application Vertical Scaling Shared Memory Architectures Geographically centralized server fault tolerance via hotswappable components Vertical Scaling Shared Disk Architectures Machines connected via fast network Contention overhead locking limit scalability highwrite volumes okay Data Warehouse applications high read volumes AWS EC2 Pricing Oct 2024 78000month highperformance instances Horizontal Scaling Shared Nothing Architectures node CPU memory disk Coordination via application layer using conventional network Geographically distributed Commodity hardware Data Replication vs Partitioning Replicates data main node Partitions subset data Replication Common Strategies Replication Single leader model Multiple leader model Leaderless model Distributed databases usually adopt one strategies LeaderBased Replication writes clients go leader Leader sends replication info followers Followers process instructions leader Clients read either leader followers LeaderBased Replication Common Strategy Relational MySQL Oracle SQL Server PostgreSQL NoSQL MongoDB RethinkDB realtime web apps Espresso LinkedIn Messaging Brokers Kafka RabbitMQ Replication Info Transmitted Followers Replication Methods Statementbased Send INSERT UPDATE DELETEs replica Simple errorprone Writeahead Log WAL bytelevel specific log every change database Logical rowbased Log relational DBs logs inserted rows modified rows deleted rows Triggerbased Changes logged separate table whenever trigger fires Synchronous vs Asynchronous Replication Synchronous Leader waits response follower Asynchronous Leader doesn’t wait confirmation Happens Leader Fails Challenges pick new Leader Node Consensus strategy use controller node configure clients start writing new leader asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data Split brain issue Leader failure detection Optimal timeout tricky Replication Lag Replication Lag refers time takes writes leader reflected followers Synchronous replication Replication lag causes writes slower system brittle number followers increases Asynchronous replication Maintains availability cost delayed eventual consistency delay called inconsistency window ReadafterWrite Consistency Scenario You’re adding comment Reddit post click Submit back main post comment show Less important users see comment immediately Implementing ReadAfterWrite Consistency Method 1 Modifiable data client’s perspective always read leader Method 2 Dynamically switch reading leader “recently updated” data example policy requests within one minute last update come leader But… Create Challenges Followers created proximal users route requests distant leaders reading modifiable data Monotonic Read Consistency Monotonic read anomalies Occur user reads values order multiple followers Monotonic read consistency Ensures user makes multiple reads read older data previously reading newer data Consistent Prefix Reads Reading data order occur different partitions replicate data different rates global write consistency Consistent Prefix Read Guarantee Ensures sequence writes happens certain order anyone reading writes see appear order